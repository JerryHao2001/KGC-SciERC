{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a5052f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import RGCNConv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ddb74d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../graph_data/\"\n",
    "# 1. Load files\n",
    "with open(datapath+'entities.json', 'r') as f:\n",
    "    entities = json.load(f)             # { entity_str: { 'canonical': text, ... }, ... }\n",
    "with open(datapath+'relation2id.json', 'r') as f:\n",
    "    rel2id = json.load(f)               # { relation_str: relation_id, ... }\n",
    "\n",
    "entity_names = list(entities.keys())\n",
    "entity2id = {name: idx for idx, name in enumerate(entity_names)}\n",
    "num_nodes = len(entity2id)\n",
    "num_rels = len(rel2id)\n",
    "\n",
    "id2cluster = { entity2id[name]: name.rsplit('_', 1)[0] for name in entity_names }\n",
    "# Build cluster → list of node‑IDs\n",
    "cluster2entity_ids = defaultdict(list)\n",
    "for node_id, cl in id2cluster.items():\n",
    "    cluster2entity_ids[cl].append(node_id)\n",
    "\n",
    "# --- 2. Load train/dev/test triples as ID tuples ---\n",
    "def load_id_triples(path):\n",
    "    triples = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            h_str, r_str, t_str = line.strip().split('\\t')\n",
    "            h_id = entity2id[h_str]\n",
    "            r_id = int(r_str)\n",
    "            t_id = entity2id[t_str]\n",
    "            triples.append((h_id, r_id, t_id))\n",
    "    return triples\n",
    "\n",
    "train_triples = load_id_triples(datapath+\"triples_train.tsv\")\n",
    "dev_triples   = load_id_triples(datapath+\"triples_dev.tsv\")\n",
    "test_triples  = load_id_triples(datapath+\"triples_test.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69e40954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Build graph from train triples ---\n",
    "src = [h for h, r, t in train_triples]\n",
    "dst = [t for h, r, t in train_triples]\n",
    "edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "edge_type  = torch.tensor([r for h, r, t in train_triples], dtype=torch.long)\n",
    "\n",
    "data = Data(edge_index=edge_index)\n",
    "data.edge_type = edge_type\n",
    "\n",
    "# --- 4. Negative sampling function ---\n",
    "def negative_sample_tails(triples, neg_rate=1):\n",
    "    examples = []\n",
    "    for h, r, t in triples:\n",
    "        examples.append((h, r, t, 1))\n",
    "        c = id2cluster[h]\n",
    "        candidates = cluster2entity_ids[c]\n",
    "        for _ in range(neg_rate):\n",
    "            t_neg = random.choice(candidates)\n",
    "            while t_neg == t:\n",
    "                t_neg = random.choice(candidates)\n",
    "            examples.append((h, r, t_neg, 0))\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ee2b840",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCNLinkPredictor(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes: int,\n",
    "        in_dim: int,\n",
    "        hidden_dim: int,\n",
    "        out_dim: int,\n",
    "        num_rels: int,\n",
    "        num_layers: int = 2,\n",
    "        dropout: float = 0.3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # learnable node and relation embeddings\n",
    "        self.node_emb = nn.Embedding(num_nodes, in_dim)\n",
    "        self.rel_emb  = nn.Embedding(num_rels, out_dim)\n",
    "        self.dropout  = nn.Dropout(dropout)\n",
    "\n",
    "        # build R-GCN layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        if num_layers == 1:\n",
    "            self.convs.append(RGCNConv(in_dim, out_dim, num_rels))\n",
    "        else:\n",
    "            # first layer\n",
    "            self.convs.append(RGCNConv(in_dim, hidden_dim, num_rels))\n",
    "            # intermediate layers\n",
    "            for _ in range(num_layers - 2):\n",
    "                self.convs.append(RGCNConv(hidden_dim, hidden_dim, num_rels))\n",
    "            # final layer\n",
    "            self.convs.append(RGCNConv(hidden_dim, out_dim, num_rels))\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        # initial node features\n",
    "        x = self.node_emb.weight  # shape: (num_nodes, in_dim)\n",
    "        # apply each R-GCN conv with residual + dropout\n",
    "        for conv in self.convs:\n",
    "            h_prev = x\n",
    "            x = conv(x, edge_index, edge_type)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            # residual if dimensions match\n",
    "            if x.shape == h_prev.shape:\n",
    "                x = x + h_prev\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4402d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 7. Training & evaluation utilities ---\n",
    "def train_epoch(neg_rate=1, batch_size=1024):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    examples = negative_sample_tails(train_triples, neg_rate)\n",
    "    random.shuffle(examples)\n",
    "\n",
    "    for i in range(0, len(examples), batch_size):\n",
    "        batch = examples[i : i+batch_size]\n",
    "        h_ids = torch.tensor([h for h,_,_,_ in batch], device=device)\n",
    "        r_ids = torch.tensor([r for _,r,_,_ in batch], device=device)\n",
    "        t_ids = torch.tensor([t for *_,t, _ in batch], device=device)\n",
    "        labels= torch.tensor([l for *_,_,l in batch], dtype=torch.float, device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # ← Moved inside the loop\n",
    "        node_embs = model(data.edge_index.to(device),\n",
    "                          data.edge_type.to(device))\n",
    "        rel_embs  = model.rel_emb.weight\n",
    "\n",
    "        e_h = node_embs[h_ids]\n",
    "        e_t = node_embs[t_ids]\n",
    "        e_r = rel_embs[r_ids]\n",
    "\n",
    "        scores = (e_h * e_r * e_t).sum(dim=1)\n",
    "        loss   = F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * len(batch)\n",
    "\n",
    "    return total_loss / len(examples)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(triples):\n",
    "    model.eval()\n",
    "    # Precompute node and relation embeddings once per evaluation\n",
    "    node_embs = model(data.edge_index.to(device), data.edge_type.to(device))\n",
    "    rel_embs  = model.rel_emb.weight.to(device)\n",
    "    ranks = []\n",
    "\n",
    "    for h, r, t in triples:\n",
    "        # score against all nodes\n",
    "        v = node_embs[h] * rel_embs[r]\n",
    "        scores = (node_embs * v).sum(dim=1)\n",
    "\n",
    "        # Restrict scoring to h's cluster\n",
    "        c = id2cluster[h]\n",
    "        candidates = cluster2entity_ids[c]\n",
    "        cand_scores = scores[candidates]\n",
    "\n",
    "        # Local ranking within cluster\n",
    "        sorted_idx = torch.argsort(cand_scores, descending=True)\n",
    "        sorted_cands = [candidates[i] for i in sorted_idx]\n",
    "        rank = sorted_cands.index(t) + 1\n",
    "        ranks.append(rank)\n",
    "\n",
    "    ranks = np.array(ranks)\n",
    "    mrr   = np.mean(1.0 / ranks)\n",
    "    hits1 = np.mean(ranks <= 1)\n",
    "    hits3 = np.mean(ranks <= 3)\n",
    "    hits10= np.mean(ranks <= 10)\n",
    "    return mrr, hits1, hits3, hits10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cd966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Instantiate model & optimizer ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RGCNLinkPredictor(\n",
    "    num_nodes=num_nodes,\n",
    "    in_dim=128,\n",
    "    hidden_dim=128,\n",
    "    out_dim=128,\n",
    "    num_rels=num_rels,\n",
    "    num_layers=3\n",
    ").to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a00c0d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ▶ loss=11.7891  Dev MRR=0.2373  Hits@1=0.0791 Hits@3=0.2396 Hits@10=0.6857\n",
      "Epoch 2 ▶ loss=4.3331  Dev MRR=0.2482  Hits@1=0.0857 Hits@3=0.2484 Hits@10=0.6989\n",
      "Epoch 3 ▶ loss=2.7609  Dev MRR=0.2486  Hits@1=0.0835 Hits@3=0.2527 Hits@10=0.6923\n",
      "Epoch 4 ▶ loss=2.1204  Dev MRR=0.2438  Hits@1=0.0791 Hits@3=0.2505 Hits@10=0.6923\n",
      "Epoch 5 ▶ loss=1.6767  Dev MRR=0.2448  Hits@1=0.0769 Hits@3=0.2527 Hits@10=0.6813\n",
      "Epoch 6 ▶ loss=1.3936  Dev MRR=0.2443  Hits@1=0.0769 Hits@3=0.2505 Hits@10=0.6901\n",
      "Epoch 7 ▶ loss=1.1739  Dev MRR=0.2538  Hits@1=0.0945 Hits@3=0.2505 Hits@10=0.6835\n",
      "Epoch 8 ▶ loss=1.0966  Dev MRR=0.2501  Hits@1=0.0857 Hits@3=0.2549 Hits@10=0.6791\n",
      "Epoch 9 ▶ loss=0.9557  Dev MRR=0.2508  Hits@1=0.0835 Hits@3=0.2769 Hits@10=0.6791\n",
      "Epoch 10 ▶ loss=0.8695  Dev MRR=0.2521  Hits@1=0.0835 Hits@3=0.2637 Hits@10=0.6659\n",
      "Epoch 11 ▶ loss=0.7943  Dev MRR=0.2529  Hits@1=0.0857 Hits@3=0.2615 Hits@10=0.6637\n",
      "Epoch 12 ▶ loss=0.7511  Dev MRR=0.2539  Hits@1=0.0901 Hits@3=0.2681 Hits@10=0.6637\n",
      "Epoch 13 ▶ loss=0.7076  Dev MRR=0.2559  Hits@1=0.0923 Hits@3=0.2725 Hits@10=0.6615\n",
      "Epoch 14 ▶ loss=0.6778  Dev MRR=0.2499  Hits@1=0.0791 Hits@3=0.2791 Hits@10=0.6747\n",
      "Epoch 15 ▶ loss=0.6554  Dev MRR=0.2458  Hits@1=0.0747 Hits@3=0.2857 Hits@10=0.6901\n",
      "Epoch 16 ▶ loss=0.6373  Dev MRR=0.2490  Hits@1=0.0835 Hits@3=0.2615 Hits@10=0.6879\n",
      "Epoch 17 ▶ loss=0.5607  Dev MRR=0.2451  Hits@1=0.0769 Hits@3=0.2593 Hits@10=0.6857\n",
      "Epoch 18 ▶ loss=0.5544  Dev MRR=0.2466  Hits@1=0.0791 Hits@3=0.2593 Hits@10=0.6879\n",
      "Epoch 19 ▶ loss=0.5307  Dev MRR=0.2476  Hits@1=0.0791 Hits@3=0.2505 Hits@10=0.6923\n",
      "Epoch 20 ▶ loss=0.4746  Dev MRR=0.2399  Hits@1=0.0725 Hits@3=0.2462 Hits@10=0.6879\n",
      "Epoch 21 ▶ loss=0.4859  Dev MRR=0.2432  Hits@1=0.0725 Hits@3=0.2505 Hits@10=0.6945\n",
      "Epoch 22 ▶ loss=0.4397  Dev MRR=0.2471  Hits@1=0.0791 Hits@3=0.2505 Hits@10=0.6967\n",
      "Epoch 23 ▶ loss=0.4335  Dev MRR=0.2481  Hits@1=0.0813 Hits@3=0.2549 Hits@10=0.6923\n",
      "Epoch 24 ▶ loss=0.4296  Dev MRR=0.2517  Hits@1=0.0901 Hits@3=0.2462 Hits@10=0.6901\n",
      "Epoch 25 ▶ loss=0.4340  Dev MRR=0.2426  Hits@1=0.0791 Hits@3=0.2308 Hits@10=0.6923\n",
      "Epoch 26 ▶ loss=0.3878  Dev MRR=0.2459  Hits@1=0.0791 Hits@3=0.2440 Hits@10=0.7055\n",
      "Epoch 27 ▶ loss=0.3727  Dev MRR=0.2474  Hits@1=0.0835 Hits@3=0.2484 Hits@10=0.6967\n",
      "Epoch 28 ▶ loss=0.3813  Dev MRR=0.2437  Hits@1=0.0835 Hits@3=0.2484 Hits@10=0.6857\n",
      "Epoch 29 ▶ loss=0.3730  Dev MRR=0.2385  Hits@1=0.0747 Hits@3=0.2418 Hits@10=0.6879\n",
      "Epoch 30 ▶ loss=0.3350  Dev MRR=0.2402  Hits@1=0.0725 Hits@3=0.2484 Hits@10=0.6857\n",
      "Epoch 31 ▶ loss=0.3373  Dev MRR=0.2440  Hits@1=0.0769 Hits@3=0.2462 Hits@10=0.6945\n",
      "Epoch 32 ▶ loss=0.3298  Dev MRR=0.2447  Hits@1=0.0813 Hits@3=0.2527 Hits@10=0.6813\n",
      "Epoch 33 ▶ loss=0.3105  Dev MRR=0.2481  Hits@1=0.0835 Hits@3=0.2747 Hits@10=0.6901\n",
      "Epoch 34 ▶ loss=0.2950  Dev MRR=0.2487  Hits@1=0.0835 Hits@3=0.2681 Hits@10=0.6945\n",
      "Epoch 35 ▶ loss=0.3045  Dev MRR=0.2448  Hits@1=0.0791 Hits@3=0.2615 Hits@10=0.6945\n",
      "Epoch 36 ▶ loss=0.2936  Dev MRR=0.2414  Hits@1=0.0791 Hits@3=0.2418 Hits@10=0.6989\n",
      "Epoch 37 ▶ loss=0.2613  Dev MRR=0.2468  Hits@1=0.0857 Hits@3=0.2527 Hits@10=0.6923\n",
      "Epoch 38 ▶ loss=0.2843  Dev MRR=0.2457  Hits@1=0.0857 Hits@3=0.2527 Hits@10=0.6857\n",
      "Epoch 39 ▶ loss=0.2635  Dev MRR=0.2421  Hits@1=0.0791 Hits@3=0.2462 Hits@10=0.6879\n",
      "Epoch 40 ▶ loss=0.2489  Dev MRR=0.2457  Hits@1=0.0813 Hits@3=0.2527 Hits@10=0.6879\n",
      "Epoch 41 ▶ loss=0.2531  Dev MRR=0.2469  Hits@1=0.0835 Hits@3=0.2462 Hits@10=0.6813\n",
      "Epoch 42 ▶ loss=0.2419  Dev MRR=0.2472  Hits@1=0.0835 Hits@3=0.2681 Hits@10=0.6835\n",
      "Epoch 43 ▶ loss=0.2340  Dev MRR=0.2531  Hits@1=0.0901 Hits@3=0.2615 Hits@10=0.6923\n",
      "Epoch 44 ▶ loss=0.2120  Dev MRR=0.2498  Hits@1=0.0857 Hits@3=0.2549 Hits@10=0.6857\n",
      "Epoch 45 ▶ loss=0.2348  Dev MRR=0.2462  Hits@1=0.0791 Hits@3=0.2571 Hits@10=0.6835\n",
      "Epoch 46 ▶ loss=0.2015  Dev MRR=0.2488  Hits@1=0.0813 Hits@3=0.2571 Hits@10=0.6791\n",
      "Epoch 47 ▶ loss=0.2412  Dev MRR=0.2513  Hits@1=0.0879 Hits@3=0.2505 Hits@10=0.6857\n",
      "Epoch 48 ▶ loss=0.2079  Dev MRR=0.2458  Hits@1=0.0813 Hits@3=0.2462 Hits@10=0.6835\n",
      "Epoch 49 ▶ loss=0.2142  Dev MRR=0.2482  Hits@1=0.0791 Hits@3=0.2549 Hits@10=0.6879\n",
      "Epoch 50 ▶ loss=0.1992  Dev MRR=0.2509  Hits@1=0.0835 Hits@3=0.2505 Hits@10=0.6967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerry\\AppData\\Local\\Temp\\ipykernel_23880\\1473257456.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_rgcn.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ▶ MRR=0.2411  Hits@1=0.0801  Hits@3=0.2269 Hits@10=0.6992\n"
     ]
    }
   ],
   "source": [
    "# --- 8. Main training loop ---\n",
    "best_mrr = 0.0\n",
    "num_epochs = 50\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    loss = train_epoch(neg_rate=5)\n",
    "    dev_mrr, dev_h1, dev_h3, dev_h10 = evaluate(dev_triples)\n",
    "    print(f\"Epoch {epoch} ▶ loss={loss:.4f}  Dev MRR={dev_mrr:.4f}  Hits@1={dev_h1:.4f} Hits@3={dev_h3:.4f} Hits@10={dev_h10:.4f}\")\n",
    "    if dev_mrr > best_mrr:\n",
    "        best_mrr = dev_mrr\n",
    "        torch.save(model.state_dict(), \"best_rgcn.pt\")\n",
    "\n",
    "# --- 9. Final test evaluation ---\n",
    "model.load_state_dict(torch.load(\"best_rgcn.pt\"))\n",
    "test_mrr, test_h1, test_h3, test_h10 = evaluate(test_triples)\n",
    "print(f\"Test ▶ MRR={test_mrr:.4f}  Hits@1={test_h1:.4f}  Hits@3={test_h3:.4f} Hits@10={test_h10:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b974e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
