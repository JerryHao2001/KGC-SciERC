{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af7cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a4537c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../graph_data/\"\n",
    "# 1. Load files\n",
    "with open(datapath+'entities.json', 'r') as f:\n",
    "    entities = json.load(f)             # { entity_str: { 'canonical': text, ... }, ... }\n",
    "with open(datapath+'relation2id.json', 'r') as f:\n",
    "    rel2id = json.load(f)               # { relation_str: relation_id, ... }\n",
    "\n",
    "# Create mappings\n",
    "entity_names = list(entities.keys())\n",
    "entity2id = {name: idx for idx, name in enumerate(entity_names)}\n",
    "id2entity = {idx: name for name, idx in entity2id.items()}\n",
    "id2rel = {rid: rel for rel, rid in rel2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8db9539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load splits\n",
    "def load_triples(path):\n",
    "    triples = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            h, r_str, t = line.strip().split('\\t')\n",
    "            triples.append((h, int(r_str), t))\n",
    "    return triples\n",
    "\n",
    "train_triples = load_triples(datapath+\"triples_train.tsv\")\n",
    "dev_triples   = load_triples(datapath+\"triples_dev.tsv\")\n",
    "test_triples  = load_triples(datapath+\"triples_test.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfd4833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Dataset for two-tower ===\n",
    "class TwoTowerDataset(Dataset):\n",
    "    def __init__(self, triples, entities, id2rel, entity2id, tokenizer, max_len=128):\n",
    "        self.triples = triples\n",
    "        self.entities = entities\n",
    "        self.id2rel = id2rel\n",
    "        self.entity2id = entity2id\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        h_str, r_id, t_str = self.triples[idx]\n",
    "        h_text = self.entities[h_str]['canonical']\n",
    "        r_text = self.id2rel[r_id]\n",
    "        t_text = self.entities[t_str]['canonical']\n",
    "\n",
    "        qr_seq = f\"{h_text} [SEP] {r_text}\"\n",
    "        qc_seq = t_text\n",
    "\n",
    "        qr_enc = self.tokenizer(qr_seq, truncation=True, padding='max_length',\n",
    "                                 max_length=self.max_len, return_tensors='pt')\n",
    "        qc_enc = self.tokenizer(qc_seq, truncation=True, padding='max_length',\n",
    "                                 max_length=self.max_len, return_tensors='pt')\n",
    "\n",
    "        return {\n",
    "            'qr_input_ids':      qr_enc.input_ids.squeeze(0),\n",
    "            'qr_attention_mask': qr_enc.attention_mask.squeeze(0),\n",
    "            'qr_token_type_ids': qr_enc.token_type_ids.squeeze(0),\n",
    "            'qc_input_ids':      qc_enc.input_ids.squeeze(0),\n",
    "            'qc_attention_mask': qc_enc.attention_mask.squeeze(0),\n",
    "            'qc_token_type_ids': qc_enc.token_type_ids.squeeze(0),\n",
    "            'tail_id':           torch.tensor(entity2id[t_str], dtype=torch.long),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba09636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. Two-tower model ===\n",
    "class TwoTowerKGBert(nn.Module):\n",
    "    def __init__(self, pretrained='bert-base-uncased', dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrained)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def encode(self, input_ids, attention_mask, token_type_ids):\n",
    "        out = self.bert(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)\n",
    "        pooled = out.pooler_output  # [CLS] embedding\n",
    "        return self.dropout(pooled)\n",
    "\n",
    "    def forward(self, qr_input_ids, qr_attention_mask, qr_token_type_ids,\n",
    "                      qc_input_ids, qc_attention_mask, qc_token_type_ids):\n",
    "        qr_emb = self.encode(qr_input_ids, qr_attention_mask, qr_token_type_ids)  # (B,d)\n",
    "        qc_emb = self.encode(qc_input_ids, qc_attention_mask, qc_token_type_ids)  # (B,d)\n",
    "        # similarity matrix: (B, B)\n",
    "        return torch.matmul(qr_emb, qc_emb.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3335ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a85e6f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Prepare DataLoaders ===\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_ds = TwoTowerDataset(train_triples, entities, id2rel, entity2id, tokenizer)\n",
    "dev_ds   = TwoTowerDataset(dev_triples,   entities, id2rel, entity2id, tokenizer)\n",
    "test_ds  = TwoTowerDataset(test_triples,  entities, id2rel, entity2id, tokenizer)\n",
    "\n",
    "# 2. Instantiate DataLoaders\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "dev_loader   = DataLoader(dev_ds,   batch_size=64, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. Initialize model, optimizer ===\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TwoTowerKGBert().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ef737cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. Precompute all tail embeddings ===\n",
    "model.eval()\n",
    "all_tail_texts = [entities[name]['canonical'] for name in entity_names]\n",
    "tail_enc = tokenizer(all_tail_texts, truncation=True, padding='longest',\n",
    "                     return_tensors='pt').to(device)\n",
    "with torch.no_grad():\n",
    "    all_tail_embs = model.encode(tail_enc.input_ids,\n",
    "                                 tail_enc.attention_mask,\n",
    "                                 tail_enc.token_type_ids)  # (|E|, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72571f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7. Training + evaluation loops ===\n",
    "def train_epoch(train_loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        # Move to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        logits = model(batch['qr_input_ids'],\n",
    "                       batch['qr_attention_mask'],\n",
    "                       batch['qr_token_type_ids'],\n",
    "                       batch['qc_input_ids'],\n",
    "                       batch['qc_attention_mask'],\n",
    "                       batch['qc_token_type_ids'])  # (B, B)\n",
    "\n",
    "        labels = torch.arange(logits.size(0), device=device)\n",
    "        loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    ranks = []\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Evaluating\"):\n",
    "        # move to GPU\n",
    "        for k,v in batch.items():\n",
    "            batch[k] = v.to(device)\n",
    "        # encode all queries in the batch\n",
    "        qr_emb = model.encode(\n",
    "            batch['qr_input_ids'],\n",
    "            batch['qr_attention_mask'],\n",
    "            batch['qr_token_type_ids']\n",
    "        )  # (B, d)\n",
    "\n",
    "        # for each example in the batch, score against all tails\n",
    "        for i, true_t in enumerate(batch['tail_id']):\n",
    "            q = qr_emb[i]                           # (d,)\n",
    "            scores = all_tail_embs @ q             # (|E|,)\n",
    "            sorted_idx = torch.argsort(scores, descending=True)\n",
    "            rank = (sorted_idx == true_t).nonzero(as_tuple=True)[0].item() + 1\n",
    "            ranks.append(rank)\n",
    "\n",
    "    ranks = np.array(ranks)\n",
    "    mrr   = np.mean(1.0 / ranks)\n",
    "    hits1 = np.mean(ranks <= 1)\n",
    "    hits3 = np.mean(ranks <= 3)\n",
    "    hits10= np.mean(ranks <= 10)\n",
    "    return mrr, hits1, hits3, hits10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aae328a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 101/101 [00:30<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:01<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ▶ loss=5.0709  dev_MRR=0.0013  Hits@10=0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 101/101 [00:30<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 ▶ loss=4.1680  dev_MRR=0.0012  Hits@10=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 101/101 [00:28<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 ▶ loss=3.7513  dev_MRR=0.0011  Hits@10=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 101/101 [00:28<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00,  9.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 ▶ loss=3.5986  dev_MRR=0.0010  Hits@10=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 101/101 [00:29<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:01<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 ▶ loss=3.5032  dev_MRR=0.0011  Hits@10=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 101/101 [00:29<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:01<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 ▶ loss=3.4946  dev_MRR=0.0010  Hits@10=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 101/101 [00:28<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 ▶ loss=3.4794  dev_MRR=0.0009  Hits@10=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 101/101 [00:28<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 ▶ loss=3.4584  dev_MRR=0.0014  Hits@10=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 101/101 [00:28<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:01<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 ▶ loss=3.5044  dev_MRR=0.0012  Hits@10=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 101/101 [00:28<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:01<00:00,  7.77it/s]\n",
      "C:\\Users\\jerry\\AppData\\Local\\Temp\\ipykernel_32044\\548728234.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_two_tower.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 ▶ loss=3.4254  dev_MRR=0.0011  Hits@10=0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 16/16 [00:02<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ▶ MRR=0.0025  Hits@1=0.0010  Hits@3=0.0010  Hits@10=0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Main loop\n",
    "num_epochs = 10\n",
    "best_mrr = 0\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    avg_loss = train_epoch(train_loader)\n",
    "    print(\"Evaluation\")\n",
    "    dev_mrr, dev_h1, dev_h3, dev_h10 = evaluate(dev_loader)\n",
    "    print(f\"Epoch {epoch} ▶ loss={avg_loss:.4f}  dev_MRR={dev_mrr:.4f}  Hits@10={dev_h10:.4f}\")\n",
    "    if dev_mrr > best_mrr:\n",
    "        best_mrr = dev_mrr\n",
    "        torch.save(model.state_dict(), \"best_two_tower.pt\")\n",
    "\n",
    "# Final test\n",
    "model.load_state_dict(torch.load(\"best_two_tower.pt\"))\n",
    "test_mrr, test_h1, test_h3, test_h10 = evaluate(test_loader)\n",
    "print(f\"Test ▶ MRR={test_mrr:.4f}  Hits@1={test_h1:.4f}  Hits@3={test_h3:.4f}  Hits@10={test_h10:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
