{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49fb23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_triples(path):\n",
    "    triples = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            h, r, t = line.strip().split()[:3]\n",
    "            triples.append((h, r, t))\n",
    "    return triples\n",
    "\n",
    "train_triples = load_triples(\"../graph_data/train.tsv\")\n",
    "dev_triples =  load_triples(\"../graph_data/dev.tsv\")\n",
    "test_triples =  load_triples(\"../graph_data/test.tsv\")\n",
    "\n",
    "\n",
    "entities = sorted({e for (h, _, t) in train_triples + dev_triples + test_triples for e in (h, t)})\n",
    "relations = sorted({r for (_, r, _) in train_triples + dev_triples + test_triples})\n",
    "ent2id = {e: i for i, e in enumerate(entities)}\n",
    "rel2id = {r: i for i, r in enumerate(relations)}\n",
    "\n",
    "\n",
    "\n",
    "def encode_cls(triples):\n",
    "    data = []\n",
    "    for h, r, t in triples:\n",
    "        data.append((ent2id[h], ent2id[t], rel2id[r]))\n",
    "    return torch.tensor(data, dtype=torch.long)\n",
    "\n",
    "train_data = encode_cls(train_triples)\n",
    "dev_data   = encode_cls(dev_triples)\n",
    "test_data  = encode_cls(test_triples)\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "dev_loader   = DataLoader(TensorDataset(dev_data),   batch_size=batch_size)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_data), batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(TensorDataset(test_data),  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) RotatE-based classifier model\n",
    "dim = 512\n",
    "\n",
    "class RotatEClassifier(nn.Module):\n",
    "    def __init__(self, num_ent, num_rel, dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ent_re = nn.Embedding(num_ent, dim)\n",
    "        self.ent_im = nn.Embedding(num_ent, dim)\n",
    "\n",
    "        self.rel_ph = nn.Embedding(num_rel, dim)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.ent_re.weight)\n",
    "        nn.init.xavier_uniform_(self.ent_im.weight)\n",
    "        nn.init.uniform_(self.rel_ph.weight, -3.1415, 3.1415)\n",
    "\n",
    "    def forward(self, h, t):\n",
    "\n",
    "        re_h, im_h = self.ent_re(h), self.ent_im(h)\n",
    "        re_t, im_t = self.ent_re(t), self.ent_im(t)\n",
    "\n",
    "        ph = self.rel_ph.weight         \n",
    "        re_r = torch.cos(ph)              \n",
    "        im_r = torch.sin(ph)\n",
    "\n",
    "        re_hr = re_h.unsqueeze(1) * re_r.unsqueeze(0) - im_h.unsqueeze(1) * im_r.unsqueeze(0)\n",
    "        im_hr = re_h.unsqueeze(1) * im_r.unsqueeze(0) + im_h.unsqueeze(1) * re_r.unsqueeze(0)\n",
    "\n",
    "        diff_re = re_hr - re_t.unsqueeze(1)\n",
    "        diff_im = im_hr - im_t.unsqueeze(1)\n",
    "\n",
    "        score = - (diff_re.abs() + diff_im.abs()).sum(dim=-1)\n",
    "        return score \n",
    "\n",
    "\n",
    "num_ent = len(entities)\n",
    "num_rel = len(relations)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = RotatEClassifier(num_ent, num_rel, dim).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "\n",
    "dev_tuple = dev_data.to(device)\n",
    "test_tuple = test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33c7346b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.0274 | Dev Acc: 0.1522\n",
      "Epoch 20 | Train Loss: 0.0120 | Dev Acc: 0.1522\n",
      "Epoch 30 | Train Loss: 0.0076 | Dev Acc: 0.1304\n",
      "Epoch 40 | Train Loss: 0.0058 | Dev Acc: 0.1087\n",
      "Epoch 50 | Train Loss: 0.0047 | Dev Acc: 0.1522\n",
      "Epoch 60 | Train Loss: 0.0040 | Dev Acc: 0.1522\n",
      "Epoch 70 | Train Loss: 0.0037 | Dev Acc: 0.1522\n",
      "Epoch 80 | Train Loss: 0.0035 | Dev Acc: 0.1522\n",
      "Epoch 90 | Train Loss: 0.0032 | Dev Acc: 0.1522\n",
      "Epoch 100 | Train Loss: 0.0031 | Dev Acc: 0.1522\n",
      "Epoch 110 | Train Loss: 0.0031 | Dev Acc: 0.1739\n",
      "Epoch 120 | Train Loss: 0.0030 | Dev Acc: 0.1957\n",
      "Epoch 130 | Train Loss: 0.0026 | Dev Acc: 0.1957\n",
      "Epoch 140 | Train Loss: 0.0026 | Dev Acc: 0.1957\n",
      "Epoch 150 | Train Loss: 0.0027 | Dev Acc: 0.1957\n",
      "Epoch 160 | Train Loss: 0.0026 | Dev Acc: 0.1957\n",
      "Epoch 170 | Train Loss: 0.0027 | Dev Acc: 0.2174\n",
      "Epoch 180 | Train Loss: 0.0027 | Dev Acc: 0.2174\n",
      "Epoch 190 | Train Loss: 0.0026 | Dev Acc: 0.2174\n",
      "Epoch 200 | Train Loss: 0.0024 | Dev Acc: 0.2174\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch[0].to(device)\n",
    "        h, t, r = batch[:,0], batch[:,1], batch[:,2]\n",
    "        scores = model(h, t)\n",
    "        loss = F.cross_entropy(scores, r)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * h.size(0)\n",
    "    if epoch % 10 == 0:\n",
    "        train_loss = total_loss / len(train_data)\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in dev_loader:\n",
    "                h,t,r = batch[0][:,0].to(device), batch[0][:,1].to(device), batch[0][:,2].to(device)\n",
    "                preds = model(h, t).argmax(dim=-1)\n",
    "                correct += (preds == r).sum().item()\n",
    "        dev_acc = correct / len(dev_data)\n",
    "        print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Dev Acc: {dev_acc:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c039249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.1957 | Test MRR: 0.4598 | Hits@1: 0.1957 | Hits@3: 0.6739\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_relation_ranking(data_tensor, ks=(1,3)):\n",
    "    model.eval()\n",
    "    ranks = []\n",
    "    with torch.no_grad():\n",
    "        for h,t,r in data_tensor:\n",
    "            h = h.unsqueeze(0).to(device); t = t.unsqueeze(0).to(device); r = r.item()\n",
    "            scores = model(h, t).squeeze(0)\n",
    "            sorted_scores, idxs = scores.sort(descending=True)\n",
    "            rank = (idxs == r).nonzero(as_tuple=False).item() + 1\n",
    "            ranks.append(rank)\n",
    "    ranks = torch.tensor(ranks, dtype=torch.float)\n",
    "    mrr = (1.0 / ranks).mean().item()\n",
    "    hits = {f\"Hits@{k}\": (ranks <= k).float().mean().item() for k in ks}\n",
    "    return mrr, hits\n",
    "\n",
    "\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        h,t,r = batch[0][:,0].to(device), batch[0][:,1].to(device), batch[0][:,2].to(device)\n",
    "        preds = model(h, t).argmax(dim=-1)\n",
    "        correct += (preds == r).sum().item()\n",
    "acc_test = correct / len(test_data)\n",
    "mrr_test, hits_test = evaluate_relation_ranking(test_tuple)\n",
    "print(f\"Test Acc: {acc_test:.4f} | Test MRR: {mrr_test:.4f} | Hits@1: {hits_test['Hits@1']:.4f} | Hits@3: {hits_test['Hits@3']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
